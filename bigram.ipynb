{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size=8\n",
    "batch_size=4\n",
    "max_iter=10000\n",
    "learning_rate=3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wizard_of_oz.txt','r',encoding='utf-8') as f:\n",
    "    text=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the length of char is 80\n",
      "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "char=sorted(set(text))\n",
    "print(' the length of char is {}'.format(len(char)))\n",
    "print(char)\n",
    "vocab_size=len(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_int={ch:i for i, ch in enumerate(char)}\n",
    "int_to_string={i:ch for i, ch in enumerate(char)}\n",
    "encode=lambda s:[string_to_int[c] for c in s]\n",
    "decode=lambda s:\"\".join([int_to_string[c] for c in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  1, 28, 39, 42, 39, 44, 32, 49,  1])"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splitting data for training and validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=int(len(text)*0.8)\n",
    "train_data=data[:n]\n",
    "val_data=data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is  tensor([1]) target is  tensor(1)\n",
      "when input is  tensor([1, 1]) target is  tensor(28)\n",
      "when input is  tensor([ 1,  1, 28]) target is  tensor(39)\n",
      "when input is  tensor([ 1,  1, 28, 39]) target is  tensor(42)\n",
      "when input is  tensor([ 1,  1, 28, 39, 42]) target is  tensor(39)\n",
      "when input is  tensor([ 1,  1, 28, 39, 42, 39]) target is  tensor(44)\n",
      "when input is  tensor([ 1,  1, 28, 39, 42, 39, 44]) target is  tensor(32)\n",
      "when input is  tensor([ 1,  1, 28, 39, 42, 39, 44, 32]) target is  tensor(49)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x=train_data[:block_size]\n",
    "y=train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context=x[:t+1]\n",
    "    target=y[t]\n",
    "    print(\"when input is \",context,'target is ',target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0117, 0.0317, 0.0861, 0.2341, 0.6364])\n"
     ]
    }
   ],
   "source": [
    "#softmax\n",
    "tensor1=torch.Tensor([1,2,3,4,5])\n",
    "softmax_tensor=F.softmax(tensor1,dim=0)\n",
    "\n",
    "print(softmax_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 100])\n"
     ]
    }
   ],
   "source": [
    "#initializing an embedding layer\n",
    "vocal_size=1000\n",
    "embedding_layer=100\n",
    "#Creating embedding layer\n",
    "embedding=nn.Embedding(vocal_size,embedding_layer)\n",
    "#initialising input\n",
    "input_indice=torch.LongTensor([1,5,3,2])\n",
    "#Applying the embedding layer\n",
    "embedding_output=embedding(input_indice)\n",
    "print(embedding_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get batch function\n",
    "def get_batch(split):\n",
    "    data=train_data if split=='train' else val_data\n",
    "    ix=torch.randint(len(data)-block_size,(batch_size,))\n",
    "    #print(ix)\n",
    "    x=torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y=torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[57, 54, 67, 60, 58, 71, 68, 74],\n",
      "        [67,  1, 73, 61, 58,  1, 54, 62],\n",
      "        [58,  0, 65, 58, 73,  1, 73, 61],\n",
      "        [57, 58, 58, 69,  1, 60, 71, 58]])\n",
      "tensor([[54, 67, 60, 58, 71, 68, 74, 72],\n",
      "        [ 1, 73, 61, 58,  1, 54, 62, 71],\n",
      "        [ 0, 65, 58, 73,  1, 73, 61, 58],\n",
      "        [58, 58, 69,  1, 60, 71, 58, 58]])\n"
     ]
    }
   ],
   "source": [
    "x, y=get_batch('train')\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table=nn.Embedding(vocab_size,vocab_size)\n",
    "    \n",
    "    def forward(self,index,target=None):\n",
    "        logit=self.token_embedding_table(index)\n",
    "        if target==None:\n",
    "            loss=None\n",
    "        else:\n",
    "         #geting shape of logits\n",
    "         B, T, C=logit.shape\n",
    "         logit=logit.view(B*T,C)\n",
    "         target=target.view(B*T)\n",
    "         loss=F.cross_entropy(logit,target)\n",
    "        \n",
    "        return logit, loss\n",
    "    \n",
    "    def generate(self,index,max_new_tokens):\n",
    "        #index is (B,T) array of indices in the current content\n",
    "        for _ in range(max_new_tokens):\n",
    "            #get prediction\n",
    "            logit, loss=self.forward(index)\n",
    "            #focus only on last step\n",
    "            logit=logit[:,-1,:] #becomes (B,C)\n",
    "            probs=F.softmax(logit,dim=-1) #(B,C)\n",
    "            index_next=torch.multinomial(probs,num_samples=1)\n",
    "            #append sampled index to the running sequence\n",
    "            index=torch.cat((index,index_next),dim=1)\n",
    "        return index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=BigramLanguageModel(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "context=torch.zeros((1,1),dtype=torch.long,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.generate(\n",
    "    context,\n",
    "    max_new_tokens=500)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "s OS SELain he his  y\n",
      "y cr amer lid mef \"fo y undrt ay ted \"  cist owis iresoothus it gire pigro rieswave't on os!\"Withokathouroitithens, pomeolle threfos ck linerd thte toss wicoy qumemery  thit Weve oulve artowe atlid Zedd tiey t\n",
      "\" as ye hear ar e? ca aind atrd is\n",
      "yoo\n",
      "s botovoffl be and s m thas trcrlfomere amard ly thindouse wec are De y,\"INGup ll thene,\"\n",
      "stylliz. \"ther, indowe f fimous's ongy amat helfupath, o?\"Wimy t therss stomand and prd s g be y: dedopes aveve Doug cot tl y\n",
      "\n",
      "nomyateas im\n"
     ]
    }
   ],
   "source": [
    "generated_char=decode(model.generate(\n",
    "    context,\n",
    "    max_new_tokens=500)[0].tolist()\n",
    ")\n",
    "print(generated_char)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4465, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer=torch.optim.AdamW(model.parameters(),lr=learning_rate)\n",
    "for iter in range(max_iter*200):\n",
    "    xb, yb=get_batch('train')\n",
    "\n",
    "    #Evluate loss\n",
    "\n",
    "    logit, loss=model.forward(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
